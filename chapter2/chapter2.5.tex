
\section{Evaluation}
Once the community partition result is retrieved by taking a certain model, a subsequent approach is to evaluate model performance by running comparisons among different models. Therefore, how to carry out comparative analysis and what metrics should be reported as benchmarks are two imperative factors to be considered. In the following sections, I will address these two questions separately by introducing several highly cited papers about comparative analysis and a number of best known metrics widely used in industry and academia.    

\subsection{Comparative Studies}
Comparative studies often run a number of methods on different datasets to explore what factors to cause the performance differences. This type of research aims to  offer model suggestions according to graph structure. As a follow-up work of \cite{leskovec2010empirical}, \cite{yang2015defining} compares 13 community scoring functions and employs them on 230 graph datasets belonging to various topics (i.e. social graphs, collaboration graphs, and purchasing graphs) and with different sizes (from hundreds of thousand to hundreds of millions of nodes and edges in graphs). The 13 scoring functions lie in four categories including internal connectivity, external connectivity, the combination of internal \& external connectivity and network model (modularity). To assess these scoring functions' community adequacy, four metrics are thereafter to considered, including separability, density, cohesiveness and clustering coefficient , which are often used to represent structural-level community coherence and compactness (details will be introduced in the next section). There are significant performance differences among all scoring functions: conductance (it measures the ratio of edges linking outside of the community) and triad participation ratio (the ratio of nodes in the same cluster forms a triad) achieves the best performance, while modularity is with poor performance.

\cite{orman2012comparative} argues that current community detection methods totally ignore the topological nature
of the communities as two methods may have similar evaluation performance but totally different community distributions. It claims that adding community topological metrics such as community-wise density, average distance, internal transitivity, and hub dominance may give more supportive understandings about the community partition result. Moreover, by testing on several real-world graph datasets as well as synthetic graphs using different types of approaches (e.g., modularity-based and diffusion-based approaches), it also empirically shows that there is no direct correlation between the model performance metrics (e.g., rand index and normalized mutual information) and community topological metrics. 

\cite{hric2014community} questions the  appropriateness to simply use the node metadata information (e.g., node category or membership) as the criteria to build up the ground truth. By running 11 different community detection models on 16 different graph datasets, it claims that there is a trivial correlation between the communities constructed by graph metadata and model-detected communities. Thus, it concludes that metadata communities are not able to fully infer graph topological structure as they are separate views for the graphs. Instead, graph metadata can be taken as either auxiliary information to enhance community partition performance or another perspective to interpret graphs.  

By employing 8 different models on Lancichinetti-Fortunato-Radicchi (LFR) benchmark graph \cite{lancichinetti2008benchmark}, \cite{yang2016comparative} summarizes how well these models can handle large-scale graph and community size recovery problems. All model performance and computing time are assessed and compared with each other. In the end, the paper offers some insights about how to choose the proper model given graph descriptive parameters such as LFR mixing parameter.

 For the proposed approach in \cite{abrahao2012separability}, eight large scale datasets are analayzed through 10 different methods for community detection. Along with the annotated communities from graph metadata, each graph dataset is associated with 11 types of community partition results. After calculating 36 types of structural properties of each filtered community from all 11 community partition results, the paper takes these structural properties as features to predict their related community detection methods via a Support Vector Machine (SVM) model.  The final comparative analysis gives researchers clear insights for community detection model selection. 

\cite{wang2015community} formulates a generalized procedure of community detection. A procedure-oriented framework
for benchmarking is proposed with four core modules including Setup, Detection Framework, Diagnoses, and Evaluation, which enables researchers to evaluate and compare various approaches through a universal pipeline. Particularly, in the Detection Framework, the paper shows an example by re-implementing 10 community detection models; in the Diagnoses module, key factors and key steps in each individual community detection model can be analyzed for improving model performance; in the Evaluation module, models can be assessed from multiple perspectives including efficiency, accuracy, effectiveness, and sensitivity. 
 
\cite{shen2010spectral} evaluates the top five graph matrices utilized in spectral clustering methods which can generate the best community partition.  The five matrices conducted in the comparative study include adjacency matrix, standard Laplacian matrix, normalized Laplacian matrix,
modularity matrix and correlation matrix. By employing k-means method on top of the decomposed eigenvectors of all matrices from a set of benchmark graphs, the paper shows that the normalized Laplacian matrix and correlation matrix achieve better performance in terms of community partition accuracy. 

\subsection{Metrics}  

The ill-defined community detection task leads to no universal standard to quantify the appropriateness of a community detection algorithm. \cite{chakraborty2017metrics} introduces a bunch of metrics as benchmarks from both community structure and community evaluation perspective. It also categorizes the metrics for overlapping and non-overlapping purposes.  In this section, we follows the taxonomy offered by \cite{chakraborty2017metrics} to group several widely used metrics into two categories: community structure (to only describe generated communities' characteristics) and community evaluation (to compare the detected communities with ground truth communities). While I won't separate metrics based on whether it is designed for overlapping communities or not because many metrics are eligible for both types of communities and many of the rest metrics for overlapping and non-overlapping community detection are with trivial difference. 

As mentioned in Table \ref{tab:c2_glossary}, given a graph $G(V,E)$, $C = \{c_{1},c_{2},...,c_{k}\}$ is the set of detected communities users generated with a specific partition model. $\Omega = \{\omega_{1},\omega_{2},...\omega_{k}\}$ is the ground truth communities given as a prior knowledge. $N = |V| = \sum_{\omega \in \Omega}|\omega|= \sum_{c \in C}|c|$  denotes the total number of the nodes in the original graph. $M= |E|$ denotes the number of total edges in the original graph. $N_{c} = |c|$ denotes the number of nodes in community $c$.

\subsubsection{Community Structure Metrics}

The structure metrics are used to measure the community intrinsic characteristics such as how well a graph community is densely connected. There are numerous metrics existing among current works and hereby I just report several most frequently used ones. In this section, given a community $c$, its varied structure metrics are formulated as $f(c)$. Table \ref{tab:c2_structure_metric} summarizes all mentioned metrics which details will be further explained in the following paragraphs.

\begin{table}
	% \scriptsize
	\centering
	%   \vspace{-3em} 
	% \renewcommand{\tabcolsep}{2pt}
	\begin{tabular}{|p{5cm}|p{9cm}|} \hline
	\textbf{Metric} &  \textbf{Definition}    \\ \hline
				Separability & $f(c) = \frac{|E_{c}^{in}|}{|E_{c}^{out}|}$ \\ \hline
				Density&$f(c) = \frac{2|E_{c}^{in}|}{N_{c}(N_{c}-1)}$ \\ \hline
				Clustering coefficient & $f(c) = \frac{T_{c}^{clo}}{T_{c}^{clo} +T_{c}^{op} }$\\ \hline 
				Cut Ratio & $f(c) = \frac{|E_{c}^{in}|}{N_{c}(N-N_{c})}$ \\ \hline
				Conductance& $f(c) = \frac{|E_{c}^{out}|}{2|E_{c}^{in}|+|E_{c}^{out}|}$ \\ \hline 
				Normalized cut & $f(c) = \frac{|E_{c}^{out}|}{2|E_{c}^{in}|+|E_{c}^{out}|} + \frac{|E_{c}^{out}|}{2(M-|E_{c}^{in}|)+|E_{c}^{out}|}$\\ \hline
				Modularity& $f(c) = \frac{|E_{c}^{in}|}{M}-\left(\frac{|E_{c}^{in}|+|E_{c}^{out}|}{2M}\right)^2$\\ \hline
				Surprise& $f(c) = -log\frac{\binom{F_c}{|E_c|}\binom{F-F_c}{M-|E_c|}}{\binom{F}{M}}$ \\ \hline 
				Significance & $f(c) =  \binom{N_c}{2}D(p_c|| p)$\\ \hline
				Permanence & $f(c) = \sum_{v \in c}\left[ \frac{I(v)}{E_{max}(v) } \times \frac{1}{D(v)}- (1-c_{in}(v))\right]$ \\ \hline
				Communitude & $f(c) = \frac{\frac{|E_c|}{M} - \left(\frac{D_c}{2M}\right)^2}{\sqrt{\left(\frac{D_c}{2M}\right)^2\left(1-\frac{D_c}{2M}\right)^2}}$\\ \hline 
	\end{tabular}
	\caption{Community Structure Metrics}
	\label{tab:c2_structure_metric}
	
\end{table} 

\textbf{Separability} measures the ratio between the numbers of edges within or on the boundary of the community $c$, which is calculated as:
\begin{equation}
f(c) = \frac{|E_{c}^{in}|}{|E_{c}^{out}|}
\end{equation}

where $|E_{c}^{in}|$ denotes the edges within the community $c$ and $|E_{c}^{out}|$ denotes the edges on the boundary of community. Higher value indicates the community is with better coherence. 

\textbf{Density} assumes that nodes in an optimized community should be densely connected to each other. It measures a community by considering the ratio of actual number of edges and the possible edge counts within community $c$.

\begin{equation}
	f(c) = \frac{2|E_{c}^{in}|}{N_{c}(N_{c}-1)}
\end{equation}

where $N_{c}$ is the number of nodes inside community $c$.  Higher score means the nodes in the community are better connected.

\textbf{Clustering coefficient} is calculated based on the number of triplet nodes within a community $c$. There are two types of triplets: If there are two edges among the three nodes in the triplet, it forms a open triplet $T_{c}^{op}$; If there are three edges existing in a triplet (meaning each pair of nodes are connected), it forms a closed triplet  $T_{c}^{clo}$.  Clustering coefficient indicates the ratio of closed triplets in the two types of triplets, which is calculated as: 
\begin{equation}
f(c) = \frac{T_{c}^{clo}}{T_{c}^{clo} +T_{c}^{op} }
\end{equation}

\textbf{Cut ratio} calculates the ratio of boundary edges out of all possible edges that leaving the community $c$, which is calculated as:
\begin{equation}
f(c) = \frac{|E_{c}^{out}|}{N_{c}(N-N_{c})}
\end{equation}
where $N$ denotes the number of nodes in the whole graph. $N_{c}(N-N_{c})$ calculates the number of possible node pairs that the community $c$ reaching to outside. Small ratio indicates the same-community nodes are likely to be grouped together and apart from the rest nodes in the graph.

\textbf{Conductance} measures the ratio of edges that community $c$ points to the inside and outside of the community. It indicates the degree of edges leaving out of current community. Higher value indicates the community $c$ has more edges connected with external communities. The conductance is calculated as:
\begin{equation}
f(c) = \frac{|E_{c}^{out}|}{2|E_{c}^{in}|+|E_{c}^{out}|}
\end{equation}

The reason that $|E_{c}^{in}|$ is calculated twice is because both the start and end nodes of these edges are inside the community $c$. 

\textbf{Normalized cut} is an extension of conductance by adding another term related to the outside community linkages, which is calculated as:

\begin{equation}
f(c) = \frac{|E_{c}^{out}|}{2|E_{c}^{in}|+|E_{c}^{out}|} + \frac{|E_{c}^{out}|}{2(M-|E_{c}^{in}|)+|E_{c}^{out}|}
\end{equation}

The first term in Normalized cut is the same as conductance, which represents the tendency that nodes in community $c$ link inside the community. Similarly, the second term represents the tendency that nodes in outside communities connect to current community $c$. $M$ is the total number of edges in the graph.

\textbf{Modularity}, as mentioned in previous chapters, is a type of scoring function to measure how well the current community surpasses random-generated communities in terms of the within-community node connection. It is calculated as:
\begin{equation}
f(c) = \frac{|E_{c}^{in}|}{M}-\left(\frac{|E_{c}^{in}|+|E_{c}^{out}|}{2M}\right)^2
\end{equation}

Derived from Modularity, \textbf{Surprise} \cite{aldecoa2013surprise,aldecoa2011deciphering} also compares the distribution of the nodes and edges in
a community to a random-emerged null model. By calculating the actual probability of a community given a partition result, it measures how unlikely that distribution happens. The calculation for each community Surprise score is showed as:

\begin{equation}
f(c) = -log\frac{\binom{F_c}{|E_c|}\binom{F-F_c}{M-|E_c|}}{\binom{F}{M}}
\end{equation}

where $F= \frac{N(N-1)}{2}$ is the maximum possible number of edges in the graph $G$. $F_c= \frac{N_c(N_c-1)}{2}$ is the maximum possible number of edges appeared in the community $c$.

\textbf{Significance} \cite{traag2013significant} converts the original community partition task to a new thought of finding dense subgraphs with a certain number of internal edges in a random graph. The Significance score of a community with size $N_c$ and density $p_c$ is calculated as its log-likelihood probability of generating it from the full graph with $N$ nodes and density $p$, which is rigorously proved  as:
\begin{equation}
f(c) = \binom{N_c}{2}\mathcal{D}(p_c|| p)
\end{equation}
where $\mathcal{D}(\cdot|| \cdot)$ denotes the Kullback-Leibler divergence.

\textbf{Permanence} \cite{chakraborty2014permanence,chakraborty2016permanence} is a vertex-based community quality metric to quantify how well the nodes will be persisted in the community instead of pulled out by other communities. For each node $v$ in community $c$, its in-community connections $I(v)$ is divided by its maximum connections $E_{max}(v)$ to each external communities. To ensure the final score in a range of 0 to 1, it is normalized by the node degree $D(v)$. $c_{in}(v)$  denotes the internal clustering coefficient of node $v$ in community $c$, which calculates the ratio of its edges within the community to all its edges. It functions as a penalty part in the permanence metric. Finally, the community score is the sum of all its nodes scores, which is calculated as:
\begin{equation}
f(c) = \sum_{v \in c}\left[ \frac{I(v)}{E_{max}(v) } \times \frac{1}{D(v)}- (1-c_{in}(v))\right]
\end{equation}



\textbf{Communitude} \cite{miyauchi2015network} quantifies the community $c$ in terms of the fraction of the number of edges
within the community using the Z-score as follows:

\begin{equation}
f(c) = \frac{\frac{|E_c|}{M} - \left(\frac{D_c}{2M}\right)^2}{\sqrt{\left(\frac{D_c}{2M}\right)^2\left(1-\frac{D_c}{2M}\right)^2}}
\end{equation}
where $D_c$ is the sum of node degrees in community $c$.

\subsubsection{Community Evaluation Metrics}

Once the community partition result $C$ is retrieved by employing a specific detection model, its performance can thereafter be evaluated by comparing with ground truth community $\Omega$. In this dissertation, various types of measurements are introduced to help quantify model performances, which are named as community evaluation metrics and showed in Table \ref{tab:c2_evaluation_metric}. The score of evaluation metric given a community partition $C$ and ground truth $\Omega$ is formulated as $f(C,\Omega)$.

\begin{table}
	% \scriptsize
	\centering
	%   \vspace{-3em} 
	% \renewcommand{\tabcolsep}{2pt}
	\begin{tabular}{|p{5.5cm}|p{8.5cm}|} \hline
		\textbf{Metric} &  \textbf{Definition}    \\ \hline 
		Purity& $f(C,\Omega) = \frac{1}{N} \sum_{k} \max_{j}N_{c_{k},\omega_{j}}$  \\ \hline  
		Precision (P)& $f(C,\Omega) = \frac{TP}{TP+FP}$ \\ \hline
		Recall (R)& $f(C,\Omega) = \frac{TP}{TP+FN}$\\  \hline
		$F_{\beta}$& $f(C,\Omega) = \frac{(\beta^{2}+1)P\times R}{\beta^{2}(P+R)}$ \\ \hline  
		Rand index& $f(C,\Omega) = \frac{TP+TN}{TP+FP+FN+TN}$ \\ \hline 
		Normalized mutual information & $ f(C,\Omega) = \frac{I(C,\Omega)}{[H(C)+H(\Omega)]/2}$ \\ \hline  
	\end{tabular}
	\caption{Community Evaluation Metrics}
	\label{tab:c2_evaluation_metric}
	
\end{table} 


To calculate \textbf{Purity}, a detected community $c$ is assigned to a label which appears most frequently on the nodes within community $c$. It measures the ratio of nodes which labels are correctly assigned in each community:
\begin{equation}
	f(C,\Omega) = \frac{1}{N} \sum_{k} \max_{j}N_{c_{k},\omega_{j}}
\end{equation}

where $N_{c_{k},\omega_{j}} = |c_{k}\cap \omega_{j}|$ denotes the number of common nodes detected in the two communities $c_k \in C $ and $\omega_j \in \Omega$.  However, purity is really sensitive to the number of communities for the original graph. If the number of communities increases, the purity score is more likely to increase as well. Therefore, it is not an ideal evaluation metric to judge whether the community partition is good or bad, especially when the number of communities is unknown.

Similarly to the evaluation in classification tasks, evaluation in community detection also builds up a confusion matrix to measure the pairwise node community relationship under four categories.  A true positive (TP) node pair means two nodes in the same ground-truth community are also assigned to the same detected community. A true negative (TN) node pair means two nodes in different ground-truth communities are also assigned to different detected communities. A false positive (FP) node pair means two nodes in different ground-truth communities are mistakenly assigned to the same detected community. And a false negative (FN) node pair means two nodes in the the same ground-truth community are mistakenly assigned to different detected communities. Using the four types of node pairs, by computing all possible node pairs in the graph  $G$, the following metrics can be retrieved including Precision, Recall, $F_\beta$ and Rand index.

\textbf{Precision} indicates the correctness ratio of all node pairs which are predicted in the same community:
\begin{equation}
f(C,\Omega) = \frac{TP}{TP+FP} 
\end{equation}

\textbf{Recall} shows the ratio of same-community node pairs in the ground truth is actually retrieved in the detected communities:
\begin{equation}
f(C,\Omega) = \frac{TP}{TP+FN} 
\end{equation}

\textbf{$F_\beta$} is the weighted harmonic mean of Precision and Recall to balance the two metrics with a weighting factor $\beta$:
\begin{equation}
f(C,\Omega) =\frac{(\beta^{2}+1)P\times R}{\beta^{2}(P+R)} 
\end{equation}

\textbf{Rand index} considers the ratio of correctly predict node pairs in all the possible pairs:
\begin{equation}
f(C,\Omega) = \frac{TP+TN}{TP+FP+FN+TN}
\end{equation}

\textbf{Normalized mutual information} (NMI) measures the model performance through entropy perspective, which is defined as: 
\begin{equation}
f(C,\Omega)  =  \frac{I(C,\Omega)}{[H(C)+H(\Omega)]/2}
\end{equation}

where $I(C,\Omega)$ refers to the mutual information of the predicted community partition $C$ with the ground truth community partition $\Omega$.  Mutual information calculates how much similar the two partitions look like, which is calculated as:
\begin{equation}
I(C,\Omega) = \sum_{k}\sum_{j}\frac{N_{c_{k},\omega_{j}}}{N} log \frac{N_{c_{k},\omega_{j}}}{N_{c_{k}}N_{\omega_{j}}}
\end{equation}

And $H(\cdot)$ is the entropy function, defined as:
\begin{equation}
H(C) = - \sum_{k} \frac{N_{c_k}}{N}log\frac{N_{c_k}}{N}
\end{equation}

NMI is always a number between 0 and 1. However, it can't correctly handle the case where detected community size is hugely different with ground truth community size. One of its variant, rNMI \cite{zhang2015evaluating}, solves this problem by comparing the NMI of two community partitions with a random community partition.
 
\subsection{Summary}
In this section, evaluation works are summarized into two tracks including comparative studies and metric introduction. The comparative studies always run empirical experiments on different graphs using various community detection models. These researches aim to find the best parameter settings for each model and explore the correlation between models and the intrinsic graph structures. As all mentioned comparative studies in this section are the best known works published in the recent decade, it gives a solid and authentic insight for the model understanding and selection. 

For metric introduction, I introduce a set of structure metrics to reveal community self-characteristics. Several evaluation metrics are also introduced to assess the model performance by comparing the detected communities with the ground truth. The structure metrics such as density and modularity are classic ones and have been widely used for years in numerous research works.  While some other structure metrics such as supervise and permanence are just recently designed which are still need to be testified in future works. As for those mentioned evaluation metrics, they are derived from classification evaluation metrics, which are all fundamental ones for all types of evaluation tasks. 